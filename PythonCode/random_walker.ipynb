{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "Parent module '' not loaded, cannot perform relative import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d19d0c6372c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mndi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: Parent module '' not loaded, cannot perform relative import"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Random walker segmentation algorithm\n",
    "from *Random walks for image segmentation*, Leo Grady, IEEE Trans\n",
    "Pattern Anal Mach Intell. 2006 Nov;28(11):1768-83.\n",
    "Installing pyamg and using the 'cg_mg' mode of random_walker improves\n",
    "significantly the performance.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse, ndimage as ndi\n",
    "\n",
    "from .._shared.utils import warn\n",
    "\n",
    "\n",
    "# executive summary for next code block: try to import umfpack from\n",
    "# scipy, but make sure not to raise a fuss if it fails since it's only\n",
    "# needed to speed up a few cases.\n",
    "# See discussions at:\n",
    "# https://groups.google.com/d/msg/scikit-image/FrM5IGP6wh4/1hp-FtVZmfcJ\n",
    "# http://stackoverflow.com/questions/13977970/ignore-exceptions-printed-to-stderr-in-del/13977992?noredirect=1#comment28386412_13977992\n",
    "try:\n",
    "    from scipy.sparse.linalg.dsolve import umfpack\n",
    "    old_del = umfpack.UmfpackContext.__del__\n",
    "\n",
    "    def new_del(self):\n",
    "        try:\n",
    "            old_del(self)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    umfpack.UmfpackContext.__del__ = new_del\n",
    "    UmfpackContext = umfpack.UmfpackContext()\n",
    "except:\n",
    "    UmfpackContext = None\n",
    "\n",
    "try:\n",
    "    from pyamg import ruge_stuben_solver\n",
    "    amg_loaded = True\n",
    "except ImportError:\n",
    "    amg_loaded = False\n",
    "from scipy.sparse.linalg import cg\n",
    "from ..util import img_as_float\n",
    "from ..filters import rank_order\n",
    "\n",
    "#-----------Laplacian--------------------\n",
    "\n",
    "\n",
    "def _make_graph_edges_3d(n_x, n_y, n_z):\n",
    "    \"\"\"Returns a list of edges for a 3D image.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_x: integer\n",
    "        The size of the grid in the x direction.\n",
    "    n_y: integer\n",
    "        The size of the grid in the y direction\n",
    "    n_z: integer\n",
    "        The size of the grid in the z direction\n",
    "    Returns\n",
    "    -------\n",
    "    edges : (2, N) ndarray\n",
    "        with the total number of edges::\n",
    "            N = n_x * n_y * (nz - 1) +\n",
    "                n_x * (n_y - 1) * nz +\n",
    "                (n_x - 1) * n_y * nz\n",
    "        Graph edges with each column describing a node-id pair.\n",
    "    \"\"\"\n",
    "    vertices = np.arange(n_x * n_y * n_z).reshape((n_x, n_y, n_z))\n",
    "    edges_deep = np.vstack((vertices[:, :, :-1].ravel(),\n",
    "                            vertices[:, :, 1:].ravel()))\n",
    "    edges_right = np.vstack((vertices[:, :-1].ravel(),\n",
    "                             vertices[:, 1:].ravel()))\n",
    "    edges_down = np.vstack((vertices[:-1].ravel(), vertices[1:].ravel()))\n",
    "    edges = np.hstack((edges_deep, edges_right, edges_down))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def _compute_weights_3d(data, spacing, beta=130, eps=1.e-6,\n",
    "                        multichannel=False):\n",
    "    # Weight calculation is main difference in multispectral version\n",
    "    # Original gradient**2 replaced with sum of gradients ** 2\n",
    "    gradients = 0\n",
    "    for channel in range(0, data.shape[-1]):\n",
    "        gradients += _compute_gradients_3d(data[..., channel],\n",
    "                                           spacing) ** 2\n",
    "    # All channels considered together in this standard deviation\n",
    "    beta /= 10 * data.std()\n",
    "    if multichannel:\n",
    "        # New final term in beta to give == results in trivial case where\n",
    "        # multiple identical spectra are passed.\n",
    "        beta /= np.sqrt(data.shape[-1])\n",
    "    gradients *= beta\n",
    "    weights = np.exp(- gradients)\n",
    "    weights += eps\n",
    "    return weights\n",
    "\n",
    "\n",
    "def _compute_gradients_3d(data, spacing):\n",
    "    gr_deep = np.abs(data[:, :, :-1] - data[:, :, 1:]).ravel() / spacing[2]\n",
    "    gr_right = np.abs(data[:, :-1] - data[:, 1:]).ravel() / spacing[1]\n",
    "    gr_down = np.abs(data[:-1] - data[1:]).ravel() / spacing[0]\n",
    "    return np.r_[gr_deep, gr_right, gr_down]\n",
    "\n",
    "\n",
    "def _make_laplacian_sparse(edges, weights):\n",
    "    \"\"\"\n",
    "    Sparse implementation\n",
    "    \"\"\"\n",
    "    pixel_nb = edges.max() + 1\n",
    "    diag = np.arange(pixel_nb)\n",
    "    i_indices = np.hstack((edges[0], edges[1]))\n",
    "    j_indices = np.hstack((edges[1], edges[0]))\n",
    "    data = np.hstack((-weights, -weights))\n",
    "    lap = sparse.coo_matrix((data, (i_indices, j_indices)),\n",
    "                            shape=(pixel_nb, pixel_nb))\n",
    "    connect = - np.ravel(lap.sum(axis=1))\n",
    "    lap = sparse.coo_matrix(\n",
    "        (np.hstack((data, connect)), (np.hstack((i_indices, diag)),\n",
    "                                      np.hstack((j_indices, diag)))),\n",
    "        shape=(pixel_nb, pixel_nb))\n",
    "    return lap.tocsr()\n",
    "\n",
    "\n",
    "def _clean_labels_ar(X, labels, copy=False):\n",
    "    X = X.astype(labels.dtype)\n",
    "    if copy:\n",
    "        labels = np.copy(labels)\n",
    "    labels = np.ravel(labels)\n",
    "    labels[labels == 0] = X\n",
    "    return labels\n",
    "\n",
    "\n",
    "def _buildAB(lap_sparse, labels):\n",
    "    \"\"\"\n",
    "    Build the matrix A and rhs B of the linear system to solve.\n",
    "    A and B are two block of the laplacian of the image graph.\n",
    "    \"\"\"\n",
    "    labels = labels[labels >= 0]\n",
    "    indices = np.arange(labels.size)\n",
    "    unlabeled_indices = indices[labels == 0]\n",
    "    seeds_indices = indices[labels > 0]\n",
    "    # The following two lines take most of the time in this function\n",
    "    B = lap_sparse[unlabeled_indices][:, seeds_indices]\n",
    "    lap_sparse = lap_sparse[unlabeled_indices][:, unlabeled_indices]\n",
    "    nlabels = labels.max()\n",
    "    rhs = []\n",
    "    for lab in range(1, nlabels + 1):\n",
    "        mask = (labels[seeds_indices] == lab)\n",
    "        fs = sparse.csr_matrix(mask)\n",
    "        fs = fs.transpose()\n",
    "        rhs.append(B * fs)\n",
    "    return lap_sparse, rhs\n",
    "\n",
    "\n",
    "def _mask_edges_weights(edges, weights, mask):\n",
    "    \"\"\"\n",
    "    Remove edges of the graph connected to masked nodes, as well as\n",
    "    corresponding weights of the edges.\n",
    "    \"\"\"\n",
    "    mask0 = np.hstack((mask[:, :, :-1].ravel(), mask[:, :-1].ravel(),\n",
    "                       mask[:-1].ravel()))\n",
    "    mask1 = np.hstack((mask[:, :, 1:].ravel(), mask[:, 1:].ravel(),\n",
    "                       mask[1:].ravel()))\n",
    "    ind_mask = np.logical_and(mask0, mask1)\n",
    "    edges, weights = edges[:, ind_mask], weights[ind_mask]\n",
    "    max_node_index = edges.max()\n",
    "    # Reassign edges labels to 0, 1, ... edges_number - 1\n",
    "    order = np.searchsorted(np.unique(edges.ravel()),\n",
    "                            np.arange(max_node_index + 1))\n",
    "    edges = order[edges.astype(np.int64)]\n",
    "    return edges, weights\n",
    "\n",
    "\n",
    "def _build_laplacian(data, spacing, mask=None, beta=50,\n",
    "                     multichannel=False):\n",
    "    l_x, l_y, l_z = tuple(data.shape[i] for i in range(3))\n",
    "    edges = _make_graph_edges_3d(l_x, l_y, l_z)\n",
    "    weights = _compute_weights_3d(data, spacing, beta=beta, eps=1.e-10,\n",
    "                                  multichannel=multichannel)\n",
    "    if mask is not None:\n",
    "        edges, weights = _mask_edges_weights(edges, weights, mask)\n",
    "    lap = _make_laplacian_sparse(edges, weights)\n",
    "    del edges, weights\n",
    "    return lap\n",
    "\n",
    "\n",
    "#----------- Random walker algorithm --------------------------------\n",
    "\n",
    "\n",
    "def random_walker(data, labels, beta=130, mode='bf', tol=1.e-3, copy=True,\n",
    "                  multichannel=False, return_full_prob=False, spacing=None):\n",
    "    \"\"\"Random walker algorithm for segmentation from markers.\n",
    "    Random walker algorithm is implemented for gray-level or multichannel\n",
    "    images.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Image to be segmented in phases. Gray-level `data` can be two- or\n",
    "        three-dimensional; multichannel data can be three- or four-\n",
    "        dimensional (multichannel=True) with the highest dimension denoting\n",
    "        channels. Data spacing is assumed isotropic unless the `spacing`\n",
    "        keyword argument is used.\n",
    "    labels : array of ints, of same shape as `data` without channels dimension\n",
    "        Array of seed markers labeled with different positive integers\n",
    "        for different phases. Zero-labeled pixels are unlabeled pixels.\n",
    "        Negative labels correspond to inactive pixels that are not taken\n",
    "        into account (they are removed from the graph). If labels are not\n",
    "        consecutive integers, the labels array will be transformed so that\n",
    "        labels are consecutive. In the multichannel case, `labels` should have\n",
    "        the same shape as a single channel of `data`, i.e. without the final\n",
    "        dimension denoting channels.\n",
    "    beta : float\n",
    "        Penalization coefficient for the random walker motion\n",
    "        (the greater `beta`, the more difficult the diffusion).\n",
    "    mode : string, available options {'cg_mg', 'cg', 'bf'}\n",
    "        Mode for solving the linear system in the random walker algorithm.\n",
    "        If no preference given, automatically attempt to use the fastest\n",
    "        option available ('cg_mg' from pyamg >> 'cg' with UMFPACK > 'bf').\n",
    "        - 'bf' (brute force): an LU factorization of the Laplacian is\n",
    "          computed. This is fast for small images (<1024x1024), but very slow\n",
    "          and memory-intensive for large images (e.g., 3-D volumes).\n",
    "        - 'cg' (conjugate gradient): the linear system is solved iteratively\n",
    "          using the Conjugate Gradient method from scipy.sparse.linalg. This is\n",
    "          less memory-consuming than the brute force method for large images,\n",
    "          but it is quite slow.\n",
    "        - 'cg_mg' (conjugate gradient with multigrid preconditioner): a\n",
    "          preconditioner is computed using a multigrid solver, then the\n",
    "          solution is computed with the Conjugate Gradient method.  This mode\n",
    "          requires that the pyamg module (http://pyamg.org/) is\n",
    "          installed. For images of size > 512x512, this is the recommended\n",
    "          (fastest) mode.\n",
    "    tol : float\n",
    "        tolerance to achieve when solving the linear system, in\n",
    "        cg' and 'cg_mg' modes.\n",
    "    copy : bool\n",
    "        If copy is False, the `labels` array will be overwritten with\n",
    "        the result of the segmentation. Use copy=False if you want to\n",
    "        save on memory.\n",
    "    multichannel : bool, default False\n",
    "        If True, input data is parsed as multichannel data (see 'data' above\n",
    "        for proper input format in this case)\n",
    "    return_full_prob : bool, default False\n",
    "        If True, the probability that a pixel belongs to each of the labels\n",
    "        will be returned, instead of only the most likely label.\n",
    "    spacing : iterable of floats\n",
    "        Spacing between voxels in each spatial dimension. If `None`, then\n",
    "        the spacing between pixels/voxels in each dimension is assumed 1.\n",
    "    Returns\n",
    "    -------\n",
    "    output : ndarray\n",
    "        * If `return_full_prob` is False, array of ints of same shape as\n",
    "          `data`, in which each pixel has been labeled according to the marker\n",
    "          that reached the pixel first by anisotropic diffusion.\n",
    "        * If `return_full_prob` is True, array of floats of shape\n",
    "          `(nlabels, data.shape)`. `output[label_nb, i, j]` is the probability\n",
    "          that label `label_nb` reaches the pixel `(i, j)` first.\n",
    "    See also\n",
    "    --------\n",
    "    skimage.morphology.watershed: watershed segmentation\n",
    "        A segmentation algorithm based on mathematical morphology\n",
    "        and \"flooding\" of regions from markers.\n",
    "    Notes\n",
    "    -----\n",
    "    Multichannel inputs are scaled with all channel data combined. Ensure all\n",
    "    channels are separately normalized prior to running this algorithm.\n",
    "    The `spacing` argument is specifically for anisotropic datasets, where\n",
    "    data points are spaced differently in one or more spatial dimensions.\n",
    "    Anisotropic data is commonly encountered in medical imaging.\n",
    "    The algorithm was first proposed in *Random walks for image\n",
    "    segmentation*, Leo Grady, IEEE Trans Pattern Anal Mach Intell.\n",
    "    2006 Nov;28(11):1768-83.\n",
    "    The algorithm solves the diffusion equation at infinite times for\n",
    "    sources placed on markers of each phase in turn. A pixel is labeled with\n",
    "    the phase that has the greatest probability to diffuse first to the pixel.\n",
    "    The diffusion equation is solved by minimizing x.T L x for each phase,\n",
    "    where L is the Laplacian of the weighted graph of the image, and x is\n",
    "    the probability that a marker of the given phase arrives first at a pixel\n",
    "    by diffusion (x=1 on markers of the phase, x=0 on the other markers, and\n",
    "    the other coefficients are looked for). Each pixel is attributed the label\n",
    "    for which it has a maximal value of x. The Laplacian L of the image\n",
    "    is defined as:\n",
    "       - L_ii = d_i, the number of neighbors of pixel i (the degree of i)\n",
    "       - L_ij = -w_ij if i and j are adjacent pixels\n",
    "    The weight w_ij is a decreasing function of the norm of the local gradient.\n",
    "    This ensures that diffusion is easier between pixels of similar values.\n",
    "    When the Laplacian is decomposed into blocks of marked and unmarked\n",
    "    pixels::\n",
    "        L = M B.T\n",
    "            B A\n",
    "    with first indices corresponding to marked pixels, and then to unmarked\n",
    "    pixels, minimizing x.T L x for one phase amount to solving::\n",
    "        A x = - B x_m\n",
    "    where x_m = 1 on markers of the given phase, and 0 on other markers.\n",
    "    This linear system is solved in the algorithm using a direct method for\n",
    "    small images, and an iterative method for larger images.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.random.seed(0)\n",
    "    >>> a = np.zeros((10, 10)) + 0.2 * np.random.rand(10, 10)\n",
    "    >>> a[5:8, 5:8] += 1\n",
    "    >>> b = np.zeros_like(a)\n",
    "    >>> b[3, 3] = 1  # Marker for first phase\n",
    "    >>> b[6, 6] = 2  # Marker for second phase\n",
    "    >>> random_walker(a, b)\n",
    "    array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 2, 2, 2, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 2, 2, 2, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 2, 2, 2, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)\n",
    "    \"\"\"\n",
    "    # Parse input data\n",
    "    if mode is None:\n",
    "        if amg_loaded:\n",
    "            mode = 'cg_mg'\n",
    "        elif UmfpackContext is not None:\n",
    "            mode = 'cg'\n",
    "        else:\n",
    "            mode = 'bf'\n",
    "    elif mode not in ('cg_mg', 'cg', 'bf'):\n",
    "        raise ValueError(\"{mode} is not a valid mode. Valid modes are 'cg_mg',\"\n",
    "                         \" 'cg' and 'bf'\".format(mode=mode))\n",
    "\n",
    "    if UmfpackContext is None and mode == 'cg':\n",
    "        warn('\"cg\" mode will be used, but it may be slower than '\n",
    "             '\"bf\" because SciPy was built without UMFPACK. Consider'\n",
    "             ' rebuilding SciPy with UMFPACK; this will greatly '\n",
    "             'accelerate the conjugate gradient (\"cg\") solver. '\n",
    "             'You may also install pyamg and run the random_walker '\n",
    "             'function in \"cg_mg\" mode (see docstring).')\n",
    "\n",
    "    if (labels != 0).all():\n",
    "        warn('Random walker only segments unlabeled areas, where '\n",
    "             'labels == 0. No zero valued areas in labels were '\n",
    "             'found. Returning provided labels.')\n",
    "\n",
    "        if return_full_prob:\n",
    "            # Find and iterate over valid labels\n",
    "            unique_labels = np.unique(labels)\n",
    "            unique_labels = unique_labels[unique_labels > 0]\n",
    "\n",
    "            out_labels = np.empty(labels.shape + (len(unique_labels),),\n",
    "                                  dtype=np.bool)\n",
    "            for n, i in enumerate(unique_labels):\n",
    "                out_labels[..., n] = (labels == i)\n",
    "\n",
    "        else:\n",
    "            out_labels = labels\n",
    "        return out_labels\n",
    "\n",
    "    # This algorithm expects 4-D arrays of floats, where the first three\n",
    "    # dimensions are spatial and the final denotes channels. 2-D images have\n",
    "    # a singleton placeholder dimension added for the third spatial dimension,\n",
    "    # and single channel images likewise have a singleton added for channels.\n",
    "    # The following block ensures valid input and coerces it to the correct\n",
    "    # form.\n",
    "    if not multichannel:\n",
    "        if data.ndim < 2 or data.ndim > 3:\n",
    "            raise ValueError('For non-multichannel input, data must be of '\n",
    "                             'dimension 2 or 3.')\n",
    "        dims = data.shape  # To reshape final labeled result\n",
    "        data = np.atleast_3d(img_as_float(data))[..., np.newaxis]\n",
    "    else:\n",
    "        if data.ndim < 3:\n",
    "            raise ValueError('For multichannel input, data must have 3 or 4 '\n",
    "                             'dimensions.')\n",
    "        dims = data[..., 0].shape  # To reshape final labeled result\n",
    "        data = img_as_float(data)\n",
    "        if data.ndim == 3:  # 2D multispectral, needs singleton in 3rd axis\n",
    "            data = data[:, :, np.newaxis, :]\n",
    "\n",
    "    # Spacing kwarg checks\n",
    "    if spacing is None:\n",
    "        spacing = np.asarray((1.,) * 3)\n",
    "    elif len(spacing) == len(dims):\n",
    "        if len(spacing) == 2:  # Need a dummy spacing for singleton 3rd dim\n",
    "            spacing = np.r_[spacing, 1.]\n",
    "        else:                  # Convert to array\n",
    "            spacing = np.asarray(spacing)\n",
    "    else:\n",
    "        raise ValueError('Input argument `spacing` incorrect, should be an '\n",
    "                         'iterable with one number per spatial dimension.')\n",
    "\n",
    "    if copy:\n",
    "        labels = np.copy(labels)\n",
    "    label_values = np.unique(labels)\n",
    "\n",
    "    # Reorder label values to have consecutive integers (no gaps)\n",
    "    if np.any(np.diff(label_values) != 1):\n",
    "        mask = labels >= 0\n",
    "        labels[mask] = rank_order(labels[mask])[0].astype(labels.dtype)\n",
    "    labels = labels.astype(np.int32)\n",
    "\n",
    "    # If the array has pruned zones, be sure that no isolated pixels\n",
    "    # exist between pruned zones (they could not be determined)\n",
    "    if np.any(labels < 0):\n",
    "        filled = ndi.binary_propagation(labels > 0, mask=labels >= 0)\n",
    "        labels[np.logical_and(np.logical_not(filled), labels == 0)] = -1\n",
    "        del filled\n",
    "    labels = np.atleast_3d(labels)\n",
    "    if np.any(labels < 0):\n",
    "        lap_sparse = _build_laplacian(data, spacing, mask=labels >= 0,\n",
    "                                      beta=beta, multichannel=multichannel)\n",
    "    else:\n",
    "        lap_sparse = _build_laplacian(data, spacing, beta=beta,\n",
    "                                      multichannel=multichannel)\n",
    "    lap_sparse, B = _buildAB(lap_sparse, labels)\n",
    "\n",
    "    # We solve the linear system\n",
    "    # lap_sparse X = B\n",
    "    # where X[i, j] is the probability that a marker of label i arrives\n",
    "    # first at pixel j by anisotropic diffusion.\n",
    "    if mode == 'cg':\n",
    "        X = _solve_cg(lap_sparse, B, tol=tol,\n",
    "                      return_full_prob=return_full_prob)\n",
    "    if mode == 'cg_mg':\n",
    "        if not amg_loaded:\n",
    "            warn(\"\"\"pyamg (http://pyamg.org/)) is needed to use\n",
    "                this mode, but is not installed. The 'cg' mode will be used\n",
    "                instead.\"\"\")\n",
    "            X = _solve_cg(lap_sparse, B, tol=tol,\n",
    "                          return_full_prob=return_full_prob)\n",
    "        else:\n",
    "            X = _solve_cg_mg(lap_sparse, B, tol=tol,\n",
    "                             return_full_prob=return_full_prob)\n",
    "    if mode == 'bf':\n",
    "        X = _solve_bf(lap_sparse, B,\n",
    "                      return_full_prob=return_full_prob)\n",
    "\n",
    "    # Clean up results\n",
    "    if return_full_prob:\n",
    "        labels = labels.astype(np.float)\n",
    "        X = np.array([_clean_labels_ar(Xline, labels, copy=True).reshape(dims)\n",
    "                      for Xline in X])\n",
    "        for i in range(1, int(labels.max()) + 1):\n",
    "            mask_i = np.squeeze(labels == i)\n",
    "            X[:, mask_i] = 0\n",
    "            X[i - 1, mask_i] = 1\n",
    "    else:\n",
    "        X = _clean_labels_ar(X + 1, labels).reshape(dims)\n",
    "    return X\n",
    "\n",
    "\n",
    "def _solve_bf(lap_sparse, B, return_full_prob=False):\n",
    "    \"\"\"\n",
    "    solves lap_sparse X_i = B_i for each phase i. An LU decomposition\n",
    "    of lap_sparse is computed first. For each pixel, the label i\n",
    "    corresponding to the maximal X_i is returned.\n",
    "    \"\"\"\n",
    "    lap_sparse = lap_sparse.tocsc()\n",
    "    solver = sparse.linalg.factorized(lap_sparse.astype(np.double))\n",
    "    X = np.array([solver(np.array((-B[i]).todense()).ravel())\n",
    "                  for i in range(len(B))])\n",
    "    if not return_full_prob:\n",
    "        X = np.argmax(X, axis=0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def _solve_cg(lap_sparse, B, tol, return_full_prob=False):\n",
    "    \"\"\"\n",
    "    solves lap_sparse X_i = B_i for each phase i, using the conjugate\n",
    "    gradient method. For each pixel, the label i corresponding to the\n",
    "    maximal X_i is returned.\n",
    "    \"\"\"\n",
    "    lap_sparse = lap_sparse.tocsc()\n",
    "    X = []\n",
    "    for i in range(len(B)):\n",
    "        x0 = cg(lap_sparse, -B[i].todense(), tol=tol)[0]\n",
    "        X.append(x0)\n",
    "    if not return_full_prob:\n",
    "        X = np.array(X)\n",
    "        X = np.argmax(X, axis=0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def _solve_cg_mg(lap_sparse, B, tol, return_full_prob=False):\n",
    "    \"\"\"\n",
    "    solves lap_sparse X_i = B_i for each phase i, using the conjugate\n",
    "    gradient method with a multigrid preconditioner (ruge-stuben from\n",
    "    pyamg). For each pixel, the label i corresponding to the maximal\n",
    "    X_i is returned.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    ml = ruge_stuben_solver(lap_sparse)\n",
    "    M = ml.aspreconditioner(cycle='V')\n",
    "    for i in range(len(B)):\n",
    "        x0 = cg(lap_sparse, -B[i].todense(), tol=tol, M=M, maxiter=30)[0]\n",
    "        X.append(x0)\n",
    "    if not return_full_prob:\n",
    "        X = np.array(X)\n",
    "        X = np.argmax(X, axis=0)\n",
    "return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.09762701e-01   1.43037873e-01   1.20552675e-01   1.08976637e-01\n",
      "    8.47309599e-02   1.29178823e-01   8.75174423e-02   1.78354600e-01\n",
      "    1.92732552e-01   7.66883038e-02]\n",
      " [  1.58345008e-01   1.05778984e-01   1.13608912e-01   1.85119328e-01\n",
      "    1.42072116e-02   1.74258599e-02   4.04367949e-03   1.66523969e-01\n",
      "    1.55631350e-01   1.74002430e-01]\n",
      " [  1.95723668e-01   1.59831713e-01   9.22958725e-02   1.56105835e-01\n",
      "    2.36548852e-02   1.27984204e-01   2.86706575e-02   1.88933783e-01\n",
      "    1.04369664e-01   8.29323880e-02]\n",
      " [  5.29111224e-02   1.54846738e-01   9.12300664e-02   1.13686790e-01\n",
      "    3.75796009e-03   1.23527099e-01   1.22419145e-01   1.23386799e-01\n",
      "    1.88749616e-01   1.36364060e-01]\n",
      " [  7.19015801e-02   8.74063908e-02   1.39526239e-01   1.20450943e-02\n",
      "    1.33353343e-01   1.34127574e-01   4.20765122e-02   2.57852595e-02\n",
      "    6.30856702e-02   7.27421542e-02]\n",
      " [  1.14039354e-01   8.77203027e-02   1.97674768e-01   2.04089621e-02\n",
      "    4.17753512e-02   1.03226190e+00   1.13062167e+00   1.05065832e+00\n",
      "    9.32621546e-02   4.88851184e-02]\n",
      " [  3.17939167e-02   2.20750282e-02   1.31265918e-01   2.76365903e-02\n",
      "    3.93164723e-02   1.07374503e+00   1.16419865e+00   1.01942026e+00\n",
      "    1.67588981e-01   1.92196816e-02]\n",
      " [  1.95291893e-01   9.37302403e-02   1.95352218e-01   1.20969104e-01\n",
      "    1.47852716e-01   1.00783756e+00   1.05656139e+00   1.02403931e+00\n",
      "    5.92280395e-02   2.37455438e-02]\n",
      " [  6.35966359e-02   8.28525989e-02   1.28294993e-02   1.38494424e-01\n",
      "    1.13320291e-01   5.30778982e-02   1.04649611e-01   1.87881022e-02\n",
      "    1.15189299e-01   1.85859240e-01]\n",
      " [  6.37137905e-02   1.33482076e-01   2.63595725e-02   1.43265441e-01\n",
      "    5.78812186e-02   3.66382724e-02   1.17302587e-01   4.02150924e-03\n",
      "    1.65788006e-01   9.39095239e-04]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "a = np.zeros((10, 10)) + 0.2 * np.random.rand(10, 10)\n",
    "a[5:8, 5:8] += 1\n",
    "#b = np.zeros_like(a)\n",
    "#b[3, 3] = 1  # Marker for first phase\n",
    "#b[6, 6] = 2  # Marker for second phase\n",
    "#random_walker(a, b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_gradients_3d(data, spacing):\n",
    "    gr_deep = np.abs(data[:, :, :-1] - data[:, :, 1:]).ravel() / spacing[2]\n",
    "    gr_right = np.abs(data[:, :-1] - data[:, 1:]).ravel() / spacing[1]\n",
    "    gr_down = np.abs(data[:-1] - data[1:]).ravel() / spacing[0]\n",
    "    return np.r_[gr_deep, gr_right, gr_down]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3840399c6155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mspacing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcompute_gradients_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-7a5a3d41d7fc>\u001b[0m in \u001b[0;36mcompute_gradients_3d\u001b[0;34m(data, spacing)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gradients_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgr_deep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgr_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgr_down\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "spacing = np.asarray((1.,) * 3)\n",
    "compute_gradients_3d(a, spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacing = np.asarray((1.,) * 3)\n",
    "spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
